{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lauradriscoll/miniconda3/envs/flex_mult/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "from numpy import linalg as LA\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pathlib import Path\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "p_code = Path(os.environ.get(\"HOME_DIR\"))\n",
    "p_data = Path(os.environ.get(\"DATA_DIR\"))\n",
    "\n",
    "net = 'stepnet'\n",
    "PATH_YANGNET = os.path.join(p_code,net) \n",
    "sys.path.insert(0, PATH_YANGNET)\n",
    "\n",
    "from task import generate_trials, rule_name, rule_index_map, rules_dict\n",
    "from network import Model, get_perf, FixedPoint_Model\n",
    "import tools\n",
    "from analysis import clustering, standard_analysis, variance\n",
    "import numpy.random as npr\n",
    "from tools_lnd import get_T_inds, gen_trials_from_model_dir, gen_X_from_model_dir, make_lil_axes\n",
    "from tools_lnd import find_closest_fp_loc, get_model_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "# #fig save path\n",
    "# ##################################################################\n",
    "fig = 'fig5'\n",
    "figpath = os.path.join(p_code,'figs',fig,fig+'_BCEFHIKLNOQR')\n",
    "if not os.path.exists(figpath):\n",
    "    os.makedirs(figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "# #Find right model dir\n",
    "# ##################################################################\n",
    "data_fldr = 'fig3'\n",
    "file = 'LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1'\n",
    "m = os.path.join(p_data,data_fldr,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_folder = 'lesion_fps_hierarchical_ward_distance_opt_clust'\n",
    "save_dir = os.path.join(m,lesion_folder)\n",
    "\n",
    "cluster_var = np.load(os.path.join(save_dir,'cluster_var.npz'))\n",
    "lesion_var = np.load(os.path.join(save_dir,'lesion_var.npz'))\n",
    "perfs_changes = lesion_var['perfs_changes']\n",
    "\n",
    "cluster_number = {}\n",
    "cluster_number['Anti Stimulus'] = 5\n",
    "cluster_number['Delayed Response'] = 2\n",
    "cluster_number['Modality2'] = 10\n",
    "cluster_number['Modality1'] = 6\n",
    "cluster_names = ['Anti Stimulus','Delayed Response','Modality2','Modality1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_label_sets(rule_trains):\n",
    "#     label_set = {}\n",
    "#     label_set['anti'] = [('anti' in rule) or ('nogo' in rule) for rule in rule_trains]\n",
    "#     label_set['delay'] = [('delay' in rule) or ('fd' in rule) for rule in rule_trains]\n",
    "#     label_set['dm2'] = ['dm2' in rule for rule in rule_trains]\n",
    "#     label_set['dm1'] = ['dm1' in rule for rule in rule_trains]\n",
    "#     label_set['dmc'] = ['dmc' in rule for rule in rule_trains]\n",
    "#     label_set['react'] = ~np.array(label_set['delay'])\n",
    "\n",
    "#     label_reverse_set = {}\n",
    "#     label_reverse_set['anti'] = ~np.array(label_set['anti'])\n",
    "#     label_reverse_set['delay'] = ~np.array(label_set['delay'])\n",
    "#     label_reverse_set['dm2'] = ['dm1' in rule for rule in rule_trains]\n",
    "#     label_reverse_set['dm1'] = ['dm2' in rule for rule in rule_trains]\n",
    "#     label_reverse_set['dmc'] = ~np.array(label_set['dmc'])\n",
    "#     label_reverse_set['react'] = ~np.array(label_set['react'])\n",
    "#     return label_set, label_reverse_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_label_sets(rule_trains):\n",
    "    \n",
    "#     rule_trains_random = np.random.permutation(rule_trains)\n",
    "#     print(rule_trains_random)\n",
    "    \n",
    "#     label_set = {}\n",
    "#     label_set['Anti'] = [('anti' in rule) for rule in rule_trains]\n",
    "#     label_set['Delay'] = [('delay' in rule) or ('fd' in rule) for rule in rule_trains]\n",
    "# #     label_set['Memory'] = [('delay' in rule) for rule in rule_trains]\n",
    "#     label_set['Modality2'] = ['dm2' in rule for rule in rule_trains]\n",
    "#     label_set['Modality1'] = ['dm1' in rule for rule in rule_trains]\n",
    "#     label_set['Random2'] = ['dm2' in rule for rule in rule_trains_random]\n",
    "#     label_set['Random3'] = ['anti' in rule for rule in rule_trains_random]\n",
    "#     label_set['Random9'] = [('delay' in rule) or ('fd' in rule) for rule in rule_trains_random]\n",
    "\n",
    "#     label_reverse_set = {}\n",
    "#     label_reverse_set['Anti'] = ~np.array(label_set['Anti'])\n",
    "#     label_reverse_set['Delay'] = ~np.array(label_set['Delay'])\n",
    "# #     label_reverse_set['Memory'] = ~np.array(label_set['Memory'])\n",
    "#     label_reverse_set['Modality2'] = ['dm1' in rule for rule in rule_trains]\n",
    "#     label_reverse_set['Modality1'] = ['dm2' in rule for rule in rule_trains]\n",
    "#     label_reverse_set['Random2'] = ['dm1' in rule for rule in rule_trains_random]\n",
    "#     label_reverse_set['Random3'] = ~np.array(label_set['Random3'])\n",
    "#     label_reverse_set['Random9'] = ~np.array(label_set['Random9'])\n",
    "#     return label_set, label_reverse_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "# #Find right model dir\n",
    "# ##################################################################\n",
    "\n",
    "# rule_trains = ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "#           'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "#           'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo']\n",
    "\n",
    "# # rule_trains = ['fdgo', 'delaygo', 'fdanti']\n",
    "\n",
    "# rule_trains_str = '_'.join(rule_trains)\n",
    "\n",
    "# # parse input arguments as:\n",
    "# rnn_type = 'LeakyRNN'\n",
    "# activation = 'softplus'\n",
    "# w_init = 'diag'\n",
    "# ruleset = 'lr'\n",
    "# n_tasks = str(len(rule_trains))\n",
    "# n_rnn = str(128)\n",
    "# l2w = float(-6)\n",
    "# l2h = float(-6)\n",
    "# l1w = float(0)\n",
    "# l1h = float(0)\n",
    "# lr = float(-6)\n",
    "# seed = str(1)\n",
    "# net_name = 'lr'+\"{:.1f}\".format(-lr)+'l2_w'+\"{:.1f}\".format(-l2w)+'_h'+\"{:.1f}\".format(-l2h)+'_'+rule_trains_str\n",
    "# data_folder = 'data/rnn/multitask/stepnet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set of networks to compare\n",
    "# rnn_type = 'LeakyRNN'\n",
    "# activation = 'softplus'\n",
    "# w_init = 'diag'\n",
    "# data_folder ='final'\n",
    "# color_set = {}\n",
    "# color_set['lr'] = 'k'\n",
    "# color_set['untrained'] = 'dodgerblue'\n",
    "# color_set['no_noise'] = 'orangered'\n",
    "\n",
    "# seed_set = [str(1),]\n",
    "# max_d = 20\n",
    "# n_rnn = str(128)\n",
    "# x_ind_counter = 0\n",
    "# ax1_xticks = []\n",
    "# method = 'average'\n",
    "# criterion = 'maxclust'\n",
    "# all_epochs = ['stim1','stim2','delay1','delay2','go1']\n",
    "# n_tasks = str(len(rule_trains))\n",
    "# seed = 1\n",
    "# lr = -7\n",
    "# sigma_rec = 1/20\n",
    "# sigma_x = 2/20\n",
    "# ruleset = 'all'\n",
    "# w_rec_coeff  = 8/10\n",
    "# net_name = 'lr'+\"{:.1f}\".format(-lr)+'l2_w'+\"{:.1f}\".format(-l2w)+'_h'+\"{:.1f}\".format(-l2h)+'_'+rule_trains_str\n",
    "# # data_folder_all = 'data/rnn/multitask/stepnet/'\n",
    "\n",
    "# net_name = 'lr'+\"{:.1f}\".format(-lr)+'l2_w'+\"{:.1f}\".format(-l2w)+'_h'+\"{:.1f}\".format(-l2h)\n",
    "\n",
    "# net_name2 = '_sig_rec'+str(sigma_rec)+'_sig_x'+str(sigma_x)+'_w_rec_coeff'+\"{:.1f}\".format(w_rec_coeff)+'_'+rule_trains_str\n",
    "\n",
    "# m = os.path.join(p,'data','rnn','multitask',net,data_folder,ruleset,\n",
    "#                         rnn_type,activation,w_init,str(len(rule_trains))+'_tasks',\n",
    "#                         str(n_rnn)+'_n_rnn',net_name+net_name2,str(seed))\n",
    "\n",
    "# net_name = 'lr'+\"{:.1f}\".format(-lr)+'l2_w'+\"{:.1f}\".format(-l2w)+'_h'+\"{:.1f}\".format(-l2h)+'_'+rule_trains_str\n",
    "# m = os.path.join(p,'data','rnn','multitask',net,'final','all',rnn_type,activation,w_init,str(len(rule_trains))+'_tasks',str(n_rnn)+'_n_rnn',net_name,str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule_set_names = ['DelayPro', 'ReactPro', 'MemoryPro', 'DelayAnti', 'ReactAnti', 'MemoryAnti',\n",
    "#               'IntegrationModality1', 'IntegrationModality2', 'ContextIntModality1', 'ContextIntModality2', 'IntegrationMultimodal',\n",
    "#               'ReactMatch2Sample', 'ReactNonMatch2Sample', 'ReactCategoryPro', 'ReactCategoryAnti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule_names = {'fdgo':'DelayPro', \n",
    "#               'reactgo':'ReactPro', \n",
    "#               'delaygo':'MemoryPro', \n",
    "#               'fdanti':'DelayAnti', \n",
    "#               'reactanti':'ReactAnti',\n",
    "#               'delayanti':'MemoryAnti',\n",
    "#               'delaydm1':'DelayD1', \n",
    "#               'delaydm2':'DelayD2', \n",
    "#               'contextdelaydm1':'ContextDelayD1', \n",
    "#               'contextdelaydm2':'ContextDelayD2', \n",
    "#               'multidelaydm':'MultiDelayD',\n",
    "#               'dmsgo':'DM2SamplePro', \n",
    "#               'dmsnogo':'DM2SampleAnti', \n",
    "#               'dmcgo':'DM2CategoryPro', \n",
    "#               'dmcnogo':'DM2CategoryAnti'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_set,label_reverse_set = make_label_sets(rule_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.patches as mpatches\n",
    "# from scipy.cluster import hierarchy\n",
    "# color_palette = ['b','c', 'm', 'y', 'r']\n",
    "# color_palette = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "#                   '#f781bf', '#a65628', '#984ea3',\n",
    "#                  '#e41a1c', '#dede00']\n",
    "# hierarchy.set_link_color_palette(color_palette)\n",
    "# alphabet = {1:'a', 2:'b', 3:'c', 4:'d', 5:'e', 6:'f', 7:'g', 8:'h', 9:'i', 10:'j', 11:'k', 12:'l', 13:'m', 14:'n', 15:'o', 16:'p', 17:'q', 18:'r', 19:'s', 20:'t', 21:'u', 22:'v', 23:'w', 24:'x', 25:'y', 26:'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from network import get_perf\n",
    "# from task import generate_trials\n",
    "# from tools_lnd import take_names\n",
    "\n",
    "# fontsize = 20\n",
    "# tick_fontsize = fontsize*.75\n",
    "# label_fontsize = fontsize*1\n",
    "# plt.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "# def plot_lesion(m,task_list,epoch,lesion_units_list,cluster_label = [],lesion_num = []):\n",
    "\n",
    "#     fig = plt.figure(figsize=(4, 4))\n",
    "#     cmap = plt.get_cmap('hsv')\n",
    "# #     c_full = cmap(0.1)\n",
    "# #     c_lesion = cmap(.6)\n",
    "#     c_full = 'dodgerblue'\n",
    "#     c_lesion = 'r'#'brown'\n",
    "#     al = .5\n",
    "#     lw = 6\n",
    "    \n",
    "#     from tools_lnd import get_model_params\n",
    "#     w_in, b_in, w_out, b_out = get_model_params(m)\n",
    "\n",
    "#     D_out = {}\n",
    "#     D_out['axes'] = w_out[:,1:]\n",
    "#     D_out['labels'] = ['W_{out} cos(theta)','W_{out} sin(theta)']\n",
    "\n",
    "#     model = FixedPoint_Model(m)\n",
    "#     hp = model.hp\n",
    "#     with tf.Session() as sess:\n",
    "#         model.restore()\n",
    "#         model._sigma=0\n",
    "#         if len(lesion_units_list)>0:\n",
    "#             model.lesion_units(sess, lesion_units_list)\n",
    "\n",
    "#         for ri in range(len(task_list)):\n",
    "#             rule = task_list[ri]\n",
    "#             trial = generate_trials(rule, hp, 'test', noise_on = False)\n",
    "#             feed_dict = tools.gen_feed_dict(model, trial, hp)\n",
    "#             h_tf = sess.run(model.h, feed_dict=feed_dict) #(n_time, n_condition, n_neuron)\n",
    "            \n",
    "#             _components = 3\n",
    "#             pca = PCA(n_components = n_components)\n",
    "#             D_pca = {}\n",
    "            \n",
    "#             if epoch in trial.epochs.keys():\n",
    "#                 T_inds = get_T_inds(trial,epoch) # grab epoch time indexing\n",
    "#             else:\n",
    "#                 T_inds = get_T_inds(trial,'go1')\n",
    "                \n",
    "#             h =  np.transpose(h_all_byrule[rule][T_inds,:,:],(2,1,0))# h_tf[:,range(1,n_trials),:],(2,1,0))\n",
    "#             Xh = np.reshape(h,(h.shape[0],-1))\n",
    "#             fp_pca = pca.fit_transform(Xh.T)\n",
    "#             D_pca['axes'] = pca.components_.T\n",
    "#             D_pca['labels'] = ['PCA '+str(x+1) for x in range(n_components)]\n",
    "\n",
    "#             for trial_i in range(3,np.shape(trial.x)[1],int(np.shape(trial.x)[1]/20)): #includes mod2 trials\n",
    "#                 c = cmap(trial.y_loc[-1,trial_i]/(2*np.pi))\n",
    "\n",
    "# #                 ax = plt.subplot(len(task_list),2,1+(2*ri))\n",
    "#                 ax = fig.add_axes([0,ri*.6,.3,.3]);\n",
    "#                 X_rule = np.dot(h_all_byrule[rule][:,trial_i,:],D_pca['axes'])\n",
    "#                 plt.plot(X_rule[:,0],X_rule[:,1],c = c_full,alpha = al,linewidth = lw)\n",
    "#                 plt.plot(X_rule[-1,0],X_rule[-1,1],'^',c = c_full,alpha = al,linewidth = lw)\n",
    "\n",
    "#                 X_dot = np.dot(h_tf[:,trial_i,:],D_pca['axes'])\n",
    "#                 plt.plot(X_dot[:,0],X_dot[:,1],c = c_lesion,alpha = al,linewidth = lw)\n",
    "#                 plt.plot(X_dot[-1,0],X_dot[-1,1],'^',c = c_lesion,alpha = al,linewidth = lw)\n",
    "                \n",
    "#                 _, rule_name, _, _ = take_names(epoch,rule)\n",
    "#                 plt.title(cluster_label[ri]+r\"$\\bf{\" + rule_name + \"}$\", y=.98, x = 1)\n",
    "\n",
    "#                 plt.xlabel(D_pca['labels'][0])\n",
    "#                 plt.ylabel(D_pca['labels'][1])\n",
    "#                 ax.spines['right'].set_visible(False)\n",
    "#                 ax.spines['top'].set_visible(False) \n",
    "#                 ax.spines['bottom'].set_visible(False)\n",
    "#                 ax.spines['left'].set_visible(False)  \n",
    "#                 ax.set_xticks([]) \n",
    "#                 ax.set_yticks([])\n",
    "\n",
    "# #                 ax = plt.subplot(len(task_list),2,2+(2*ri))\n",
    "#                 ax = fig.add_axes([.5,ri*.6,.3,.3]);\n",
    "#                 X_rule = np.dot(h_all_byrule[rule][:,trial_i,:],D_out['axes'])\n",
    "#                 plt.plot(X_rule[:,0],X_rule[:,1],c = c_full,alpha = al,linewidth = lw)\n",
    "#                 plt.plot(X_rule[-1,0],X_rule[-1,1],'^',c = c_full,alpha = al,linewidth = lw)\n",
    "\n",
    "#                 X_dot = np.dot(h_tf[:,trial_i,:],D_out['axes'])\n",
    "#                 plt.plot(X_dot[:,0],X_dot[:,1],c = c_lesion,alpha = al,linewidth = lw)\n",
    "#                 plt.plot(X_dot[-1,0],X_dot[-1,1],'^',c = c_full,alpha = al,linewidth = lw)\n",
    "\n",
    "#                 plt.xlabel('OUT 1')\n",
    "#                 plt.ylabel('OUT 2')\n",
    "#                 ax.spines['right'].set_visible(False)\n",
    "#                 ax.spines['top'].set_visible(False) \n",
    "#                 ax.spines['bottom'].set_visible(False)\n",
    "#                 ax.spines['left'].set_visible(False)  \n",
    "#                 ax.set_xticks([]) \n",
    "#                 ax.set_yticks([])\n",
    "                \n",
    "\n",
    "#     figname = 'viz_traj_'+'_'.join(task_list)+str(lesion_num)\n",
    "#     plt.savefig(os.path.join(figpath,figname+'.pdf'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_all_byepoch, h_all_byrule, _, _, _, _ = make_h_all(m,mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lesion cluster\n",
    "# n_components = 2\n",
    "# task_list = ['reactgo', 'delaygo']\n",
    "# cluster = cluster_number['Delayed Response']+1\n",
    "# lesion_units_list = cluster_var['lesion_units_list'][cluster]\n",
    "# epoch = 'go1'\n",
    "# plot_lesion(m,task_list,epoch,lesion_units_list,\n",
    "#             cluster_label = ['Task w/o Delayed Response \\n motif : ','Task w Delayed Response \\n motif : '],\n",
    "#             lesion_num = cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lesion cluster\n",
    "# task_list = ['delaygo', 'delayanti']\n",
    "# cluster = cluster_number['Anti Stimulus']+1\n",
    "# lesion_units_list = cluster_var['lesion_units_list'][cluster]\n",
    "# epoch = 'stim1'\n",
    "# plot_lesion(m,task_list,epoch,lesion_units_list,\n",
    "#             cluster_label = ['Task w/o Anti Stimulus \\n motif : ','Task w Anti Stimulus \\n motif : '],lesion_num = cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lesion cluster\n",
    "# task_list = ['contextdelaydm1','contextdelaydm2']\n",
    "# cluster = cluster_number['Modality2']+1\n",
    "# lesion_units_list = cluster_var['lesion_units_list'][cluster]\n",
    "# epoch = 'go1'\n",
    "# plot_lesion(m,task_list,epoch,lesion_units_list,\n",
    "#             cluster_label = ['Task w/o Modality 2 \\n motif : ','Task w Modality 2 \\n motif : '],lesion_num = cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lesion cluster\n",
    "# task_list = ['contextdelaydm2','contextdelaydm1']\n",
    "# cluster = cluster_number['Modality1']+1\n",
    "# lesion_units_list = cluster_var['lesion_units_list'][cluster]\n",
    "# epoch = 'go1'\n",
    "# plot_lesion(m,task_list,epoch,lesion_units_list,\n",
    "#             cluster_label = ['Task w/o Modality 1 \\n motif : ','Task w Modality 1 \\n motif : '],lesion_num = cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tools_lnd import remove_spines, get_xlim_diff, get_ylim_diff\n",
    "# def make_lil_axes(ax,axes_labels,fontsize = 20,fac_len = 10):\n",
    "    \n",
    "#     remove_spines(ax)\n",
    "\n",
    "#     x1,x2,x_diff = get_xlim_diff(ax)\n",
    "#     y1,y2,y_diff = get_ylim_diff(ax)\n",
    "    \n",
    "#     if len(axes_labels)>2:\n",
    "#         z1,z2,z_diff = get_zlim_diff(ax)\n",
    "        \n",
    "#         plt.plot([x1,x1+x_diff/fac_len],[y1,y1],[z1,z1],'-k')\n",
    "#         plt.plot([x1,x1],[y1,y1+y_diff/fac_len],[z1,z1],'-k')\n",
    "#         plt.plot([x1,x1],[y1,y1],[z1,z1+z_diff/fac_len],'-k')\n",
    "        \n",
    "#         ax.text(x1,y1-y_diff/8,z1,axes_labels[0],(1,0,0),\n",
    "#             horizontalalignment='left',\n",
    "#             verticalalignment='top',\n",
    "#                  fontsize = fontsize)\n",
    "#         ax.text(x1-x_diff/8,y1+y_diff/5,z1,axes_labels[1],(0,1,0),\n",
    "#             horizontalalignment='left',\n",
    "#             verticalalignment='bottom',\n",
    "#                  fontsize = fontsize)\n",
    "#         ax.text(x1-x_diff/15,y1,z1+z_diff/5,axes_labels[2],\n",
    "#             horizontalalignment='right',\n",
    "#             verticalalignment='bottom',\n",
    "#                  fontsize = fontsize)\n",
    "        \n",
    "#         ax.set_zticks([])\n",
    "        \n",
    "#     else:\n",
    "#         plt.plot([x1,x1+x_diff/10],[y1,y1],'-k')\n",
    "#         plt.plot([x1,x1],[y1,y1+y_diff/10],'-k')\n",
    "\n",
    "#         plt.text(x1,y1-y_diff/50,axes_labels[0],\n",
    "#             horizontalalignment='left',\n",
    "#             verticalalignment='top',\n",
    "#                  fontsize = fontsize)\n",
    "#         plt.text(x1-x_diff/18,y1,axes_labels[1], #/6\n",
    "#             horizontalalignment='left',\n",
    "#             verticalalignment='bottom',\n",
    "#                  fontsize = fontsize,\n",
    "#                  rotation = 90)\n",
    "        \n",
    "#     ax.set_yticks([])\n",
    "#     ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rule in ['contextdelaydm1','contextdelaydm2']:#\n",
    "#     model = FixedPoint_Model(m)\n",
    "#     with tf.Session() as sess:\n",
    "#         model.restore()\n",
    "#         model._sigma=0\n",
    "\n",
    "# #         model.lesion_units(sess, lesion_units)\n",
    "#         # get all connection weights and biases as tensorflow variables\n",
    "#         var_list = model.var_list\n",
    "#         # evaluate the parameters after training\n",
    "#         params = [sess.run(var) for var in var_list]\n",
    "#         # get hparams\n",
    "#         hparams = model.hp\n",
    "#         # create a trial\n",
    "#         trial = generate_trials(rule, hparams, mode='test', noise_on=False, batch_size=40)# get feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_ax_nice(ax, ax_labels, plot_zero_plane = True):\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['bottom'].set_visible(False)\n",
    "#     ax.spines['left'].set_visible(False)\n",
    "#     ax.set_yticks([])\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_zticks([])\n",
    "#     epoch_name_ax, rule_name_ax, _, _ = take_names(ax_labels[0],ax_labels[1])\n",
    "#     ax.set_xlabel(r\"$\\bf{\"+rule_name_ax+\"}$\"+' \\n '+epoch_name_ax+' State PC1', labelpad=0)\n",
    "#     ax.set_ylabel(r\"$\\bf{\"+rule_name_ax+\"}$\"+' \\n '+epoch_name_ax+' State PC2', labelpad=0)\n",
    "#     ax.set_zlabel(r\"$\\bf{\"+rule_name_ax+\"}$\"+' \\n '+epoch_name_ax+' State PC3', labelpad=0)\n",
    "    \n",
    "#     [x1,x2] = ax.get_xlim()\n",
    "#     [y1,y2] = ax.get_ylim()\n",
    "#     ax.set_xlim([x1+.1*x1,x2+.1*x2])\n",
    "#     ax.set_ylim([y1+.1*y1,y2+.1*y2])\n",
    "#     [x1,x2] = ax.get_xlim()\n",
    "#     [y1,y2] = ax.get_ylim()\n",
    "    \n",
    "#     if plot_zero_plane:\n",
    "#         xx, yy = np.meshgrid(np.linspace(x1, x2, num=2), np.linspace(y1, y2, num=2))\n",
    "#         z = xx*0\n",
    "#         ax.plot_surface(xx, yy, z, alpha=0.1)\n",
    "#         ax.set_zlabel(r\"$\\bf{Output}$\"+r'$\\cos{\\theta}$',labelpad=-10)\n",
    "# #         ax.text(x1, y1, 0, 'Output Null', (1,0,0))\n",
    "#     elif len(zlabel)>0:\n",
    "#         ax.set_zlabel(zlabel,labelpad=-10)\n",
    "#     ax.set_zlim([-1.1,1.1])\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     ax.set_zticks([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_N3D(ax, X, D, clist, linewidth = 6, alpha = .5, linestyle = '-'):\n",
    "#     \"\"\"Plot activity is some 2D space.\n",
    "\n",
    "#         Args:\n",
    "#             X: neural activity in Trials x Time x Neurons\n",
    "#             D: Neurons x 2 plotting dims\n",
    "#         \"\"\"\n",
    "\n",
    "#     cmap=plt.get_cmap('rainbow')\n",
    "#     S = np.shape(X)[0]\n",
    "    \n",
    "#     for s in range(S):\n",
    "\n",
    "#         if isinstance(clist, str) :\n",
    "#             c = clist\n",
    "#         elif len(clist)==1:\n",
    "#             c = clist[0]\n",
    "#         else:\n",
    "#             c = cmap(clist[s]/max(clist))\n",
    "\n",
    "#         X_trial = np.dot(X[s,:,:],D.T)\n",
    "#         ax.plot3D(X_trial[:,0],X_trial[:,1],X_trial[:,2],linestyle,c = c, linewidth = linewidth, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tools_lnd import make_FP_axs, get_model_params #get_filename, \n",
    "# def compare_fp_lesions(m,cluster_var,lesion_cluster,rule_set,color_by = 'stim',n_components = 3,fontsize=20,\n",
    "#                        review = False, epoch_set = [], q_thresh = 1e-3,t = 0, ri_axs = 0, view_init = [-51,30], \n",
    "#                        epoch_ri=[]):\n",
    "    \n",
    "#     if review:\n",
    "#         lf = 'lesion_fps_review'\n",
    "#     else:\n",
    "#         lf = 'lesion_fps'\n",
    "        \n",
    "#     lesion_folder = 'lesion_fps_hierarchical_ward_distance_opt_clust'\n",
    "#     cmap = plt.get_cmap('hsv')\n",
    "#     c_full = 'dodgerblue'#cmap(0.1)\n",
    "#     c_lesion = 'r'#'brown'#cmap(.6)\n",
    "#     h_all_byepoch, h_all_byrule, _, _ = make_h_all(m)\n",
    "    \n",
    "#     plt.rcParams.update({'font.size': fontsize})\n",
    "#     tick_fontsize = fontsize*.75\n",
    "#     label_fontsize = fontsize*1\n",
    "\n",
    "#     for ri in range(len(task_list)):\n",
    "#         rule = task_list[ri]\n",
    "#         trial = gen_trials_from_model_dir(m,rule,noise_on = False)\n",
    "#         B = np.shape(trial.y_loc)[1]\n",
    "#         N = np.shape(trial.y_loc)[1]\n",
    "#         trial_set = range(0,B,int(B/10))\n",
    "        \n",
    "#         if len(epoch_ri)==0:\n",
    "#             epoch = epoch_set[ri_axs]\n",
    "#         else:\n",
    "#             epoch =  epoch_ri  \n",
    "            \n",
    "#         rule = rule_set[ri_axs]\n",
    "#         trial = gen_trials_from_model_dir(m,rule,noise_on = False)\n",
    "#         filename,_ = get_filename(trial,epoch,t)\n",
    "#         f = os.path.join(m,'tf_fixed_pts_all_init',rule,filename+'.npz')    \n",
    "#         D_use = make_FP_axs(f, m, rule, epoch, axs = 'pca_h', clust = 'False')\n",
    "#         w_in, b_in, w_out, b_out = get_model_params(m)\n",
    "\n",
    "# #         D_use = -D_use\n",
    "#         if rule == 'delaygo':\n",
    "#             D_use = -D_use\n",
    "#         else:\n",
    "#             D_use[:,1] = -D_use[:,1]\n",
    "            \n",
    "#         D_use[:,2] = w_out[:,2]\n",
    "#         axes_labels = [epoch, rule]\n",
    "\n",
    "#         epoch_list = sorted(trial.epochs.items(), key=lambda x: x[1])\n",
    "        \n",
    "#         if len(epoch_set)==0:\n",
    "#             epoch_set = [epoch_list[x][0] for x in range(len(epoch_list))]\n",
    "\n",
    "#         for trial_num in [t,]:##range(0,B,int(B/5))\n",
    "#             out_theta = int(180*trial.y_loc[-1,trial_num]/np.pi)\n",
    "\n",
    "#             for plot_num in range(0,len(epoch_set)):\n",
    "                \n",
    "#                 fig = plt.figure(figsize=(7,7),tight_layout=True,facecolor='white')\n",
    "\n",
    "#                 epoch = epoch_set[plot_num]\n",
    "#                 epoch_name, task_name, _, _ = take_names(epoch,rule)\n",
    "\n",
    "#                 ax = plt.subplot(1,1,1, projection='3d')\n",
    "#                 w_color = .005\n",
    "#                 ax.w_xaxis.set_pane_color((w_color, w_color, w_color, w_color))\n",
    "#                 ax.w_yaxis.set_pane_color((w_color, w_color, w_color, w_color))\n",
    "#                 ax.w_zaxis.set_pane_color((w_color, w_color, w_color, w_color))\n",
    "\n",
    "#                 lesion_units_list = cluster_var['lesion_units_list'][lesion_cluster]\n",
    "                \n",
    "#                 if epoch[0]=='s':\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,trial_num)\n",
    "#                 elif rule[0]=='d':\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,0)\n",
    "#                 else:\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,trial_num)\n",
    "                    \n",
    "#                 f = os.path.join(m,lesion_folder,lf,'tf_fixed_pts_lesion'+str(lesion_cluster),rule,filename)\n",
    "#                 c = c_lesion\n",
    "                \n",
    "#                 plot_FP_jitter_3D_lesion(lesion_units_list,ax,m,D_use,rule,trial_num,epoch,f,\n",
    "#                                          rand_step_coef = 0,\n",
    "#                                          al = .2, \n",
    "#                                          linestyle = '-', \n",
    "#                                          n_steps = 60,\n",
    "#                                          n_jit = 0\n",
    "#                                          ,c = c, \n",
    "#                                          q_thresh = q_thresh)\n",
    "\n",
    "#                 lesion_units_list = []\n",
    "                \n",
    "#                 if epoch[0]=='s':\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,trial_num)\n",
    "#                 elif rule[0]=='d':\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,0)\n",
    "#                 else:\n",
    "#                     filename,_ = get_filename_fp(trial,epoch,trial_num)\n",
    "                    \n",
    "#                 f = os.path.join(m,lesion_folder,lf,'tf_fixed_pts_lesion'+str(0),rule,filename)\n",
    "#                 c = c_full\n",
    "\n",
    "#                 plot_FP_jitter_3D_lesion(lesion_units_list,ax,m,D_use,rule,trial_num,epoch,f,\n",
    "#                                          rand_step_coef = 0,\n",
    "#                                          al = .2, \n",
    "#                                          linestyle = '-', \n",
    "#                                          n_steps = 60,\n",
    "#                                          n_jit = 0,\n",
    "#                                          c = c, \n",
    "#                                          q_thresh = q_thresh)\n",
    "\n",
    "#                 tit = 'Task : '+ r\"$\\bf{\" + task_name + \"}$\" +'\\n Period : '+ r\"$\\bf{\" + epoch_name.capitalize() + \"}$\"\n",
    "#                 plt.title(tit,fontsize = fontsize,y = .9)\n",
    "\n",
    "#                 ax.set_xlim([-1.2,1.2])\n",
    "#                 ax.set_ylim([-1.2,1.2]) \n",
    "#                 make_ax_nice(ax,axes_labels)\n",
    "                \n",
    "#                 ax.set_yticks([])\n",
    "#                 ax.set_xticks([])\n",
    "#                 ax.set_zticks([])\n",
    "                \n",
    "#                 ax.view_init(azim=view_init[0], elev=view_init[1]) #(azim=-51, elev=30)\n",
    "#                 ax.dist = 12\n",
    "            \n",
    "\n",
    "#                 figname = 'lesion'+str(lesion_cluster)+'_'+rule+'_'+epoch+'_'+str(out_theta)\n",
    "#                 if not os.path.exists(os.path.join(figpath,'vis_fp_lesion')):\n",
    "#                     os.makedirs(os.path.join(figpath,'vis_fp_lesion'))\n",
    "#                 plt.savefig(os.path.join(figpath,'vis_fp_lesion',figname+'.pdf'))\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_FP_jitter_3D_lesion(lesion_units_list,ax,m,D_use,rule,t_num,fp_epoch,f,\n",
    "#                    xlabel = 'FP set PC1',ylabel = 'FP set PC2',rand_step_coef = 0.1,n_steps = 100,\n",
    "#                    lw = 3,al = .6,linestyle = '-',n_jit = 0,c = 'k', q_thresh = 1e-3):#, q_thresh = 1e-8\n",
    "\n",
    "#     ms = 20\n",
    "#     lw = 6\n",
    "    \n",
    "#     fp_struct = np.load(f)\n",
    "#     step_fps = fp_struct['xstar']\n",
    "    \n",
    "# #     if fp_epoch=='stim1':\n",
    "# #         fp_use = np.where(fp_struct['qstar']<q_thresh/100)[0] \n",
    "# #     else:\n",
    "# #         fp_use = np.where(fp_struct['qstar']<q_thresh)[0]\n",
    "        \n",
    "#     fp_use = np.where(fp_struct['qstar']<q_thresh)[0]\n",
    "    \n",
    "    \n",
    "#     sorted_fps = fp_struct['xstar'][fp_use,:]\n",
    "  \n",
    "#     fp_project = np.dot(sorted_fps,D_use)\n",
    "\n",
    "#     # runs jitters around fps\n",
    "#     stable = np.empty(len(sorted_fps))\n",
    "#     for fp_ind in range(len(sorted_fps)):\n",
    "\n",
    "#         dst_scale = 300\n",
    "\n",
    "#         facecolors_3d = c\n",
    "#         facecolors_2d = c\n",
    "#         edgecolors = 'w'\n",
    "\n",
    "#         for jit in range(n_jit):\n",
    "#             h0 = sorted_fps[fp_ind,:] + rand_step_coef*npr.randn(N)\n",
    "#             h_t = vanilla_run_with_h0(params, x_t, h0, hp)\n",
    "#             jitter = np.dot(h_t,D_use)\n",
    "#             ax.plot3D(jitter[:,0],jitter[:,1],jitter[:,2],'-',c = 'k',linewidth = 3)\n",
    "\n",
    "\n",
    "#         if fp_epoch=='stim1':\n",
    "#             ax.scatter(fp_project[fp_ind,0],fp_project[fp_ind,1],fp_project[fp_ind,2],'o',\n",
    "#                       s = dst_scale, edgecolors = edgecolors, facecolors = facecolors_3d, alpha = al)\n",
    "#         else:\n",
    "#             ax.scatter(fp_project[fp_ind,0],fp_project[fp_ind,1],fp_project[fp_ind,2],'o',\n",
    "#                       s = dst_scale, edgecolors = edgecolors, facecolors = facecolors_3d, alpha = al)\n",
    "        \n",
    "#     model = Model(m)\n",
    "#     with tf.Session() as sess:\n",
    "#         model.restore()\n",
    "#         model._sigma=0\n",
    "#         if len(lesion_units_list)>0:\n",
    "#             model.lesion_units(sess, lesion_units_list)\n",
    "#         hp = model.hp\n",
    "#         alpha = hp['dt']/hp['tau']\n",
    "#         var_list = model.var_list\n",
    "#         params = [sess.run(var) for var in var_list]\n",
    "\n",
    "#         trial = generate_trials(rule, hp, mode='test',noise_on=False)\n",
    "#         feed_dict = tools.gen_feed_dict(model, trial, hp)\n",
    "#         h_tf, _ = sess.run([model.h, model.y_hat], feed_dict=feed_dict) #(n_time, n_condition, n_neuron)\n",
    "#         T,S,N = np.shape(h_tf)\n",
    "#         T_inds = get_T_inds(trial,fp_epoch) # grab epoch time indexing\n",
    "#         x_t = np.matlib.repmat(trial.x[T_inds[1],t_num,:],n_steps,1)\n",
    "            \n",
    "            \n",
    "#         #runs one state for n_steps starting from initial conditions\n",
    "#         for jit in range(1):\n",
    "#             h0 = h_tf[T_inds[0],t_num,:]\n",
    "#             h_t = vanilla_run_with_h0(params, x_t, h0, hp)\n",
    "#             jitter = np.dot(h_t,D_use)\n",
    "#             ax.plot3D(jitter[:,0],jitter[:,1],jitter[:,2],'-',c = c,alpha = .5, linewidth = lw)\n",
    "#             ax.plot3D(jitter[:,0],jitter[:,1],jitter[:,2],'-k',linewidth = lw/2)\n",
    "#             ax.plot3D(jitter[:1,0],jitter[:1,1],jitter[:1,2],'x',c = c,markersize = ms,markeredgewidth = 3)\n",
    "#             ax.plot3D(jitter[-2:-1,0],jitter[-2:-1,1],jitter[-2:-1,2],'^',c = c,markersize = ms,markeredgewidth = 3)\n",
    "#             ax.plot3D(jitter[:1,0],jitter[:1,1],jitter[:1,2],'xk',markersize = ms/2,markeredgewidth = 1)\n",
    "#             ax.plot3D(jitter[-2:-1,0],jitter[-2:-1,1],jitter[-2:-1,2],'^k',markersize = ms/2,markeredgewidth = 1)\n",
    "         \n",
    "#     ax.dist = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lesion_endpt_diff(lesion_units_list,m,rule,n_steps = 100):#, q_thresh = 1e-8\n",
    "        \n",
    "#     model = Model(m)\n",
    "#     with tf.Session() as sess:\n",
    "#         model.restore()\n",
    "#         model._sigma=0\n",
    "#         if len(lesion_units_list)>0:\n",
    "#             model.lesion_units(sess, lesion_units_list)\n",
    "#         hp = model.hp\n",
    "#         alpha = hp['dt']/hp['tau']\n",
    "#         var_list = model.var_list\n",
    "#         params = [sess.run(var) for var in var_list]\n",
    "\n",
    "#         trial = generate_trials(rule, hp, mode='test',noise_on=False)\n",
    "#         feed_dict = tools.gen_feed_dict(model, trial, hp)\n",
    "#         h_lesion, _ = sess.run([model.h, model.y_hat], feed_dict=feed_dict) #(n_time, n_condition, n_neuron)\n",
    "\n",
    "# #     model = Model(m)\n",
    "# #     with tf.Session() as sess:\n",
    "# #         model.restore()\n",
    "# #         model._sigma=0\n",
    "# #         hp = model.hp\n",
    "# #         alpha = hp['dt']/hp['tau']\n",
    "# #         var_list = model.var_list\n",
    "# #         params = [sess.run(var) for var in var_list]\n",
    "\n",
    "# #         trial = generate_trials(rule, hp, mode='test',noise_on=False)\n",
    "# #         feed_dict = tools.gen_feed_dict(model, trial, hp)\n",
    "# #         h_tf, _ = sess.run([model.h, model.y_hat], feed_dict=feed_dict) #(n_time, n_condition, n_neuron)\n",
    "        \n",
    "#     return h_lesion #, h_tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_filename_fp(trial, epoch,t):\n",
    "#     ind_stim_loc  = str(int(180*trial.y_loc[-1,t]/np.pi))\n",
    "#     nonzero_stim = trial.stim_locs[0,:]<100\n",
    "#     stim_names = '_'.join(str(int(180*x/np.pi)) for x in trial.stim_locs[t,nonzero_stim])\n",
    "#     filename = epoch+'_trial'+str(t)+'_x'+stim_names+'_y'+ind_stim_loc+'.npz'\n",
    "\n",
    "#     return filename, ind_stim_loc\n",
    "\n",
    "\n",
    "# def get_filename(trial, epoch,t):\n",
    "#     ind_stim_loc  = 180*trial.y_loc[-1,t]/np.pi\n",
    "#     filename = epoch+'_'+str(round(ind_stim_loc,2))+'.npz'\n",
    "\n",
    "#     return filename, ind_stim_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vanilla_run_with_h0(params, x_t, h0, hparams):\n",
    "\n",
    "#     dt = hparams['dt']\n",
    "#     tau = hparams['tau']\n",
    "#     alpha = dt/tau\n",
    "#     activation = hparams['activation']\n",
    "\n",
    "#     h = h0\n",
    "#     h_t = []\n",
    "#     h_t.append(np.expand_dims(h0,axis=1))\n",
    "#     for x in x_t:\n",
    "#         h = rnn_vanilla(params, np.squeeze(h), np.squeeze(x.T), alpha, activation)\n",
    "#         h_t.append(np.expand_dims(h,axis=1))\n",
    "\n",
    "#     h_t = np.squeeze(np.array(h_t))  \n",
    "#     return h_t\n",
    "\n",
    "# def rnn_vanilla(params, h, x, alpha, activation):\n",
    "\n",
    "#     if activation == 'softplus':\n",
    "#         _activation = lambda x: np.log(np.exp(x) + 1)\n",
    "#     elif activation == 'tanh':\n",
    "#         _activation = lambda x: np.tanh(x)\n",
    "#     elif activation == 'relu':\n",
    "#         _activation = lambda x: x * (x > 0)\n",
    "#     elif activation == 'power':\n",
    "#         _activation = lambda x: (x * (x > 0))**2\n",
    "#     elif activation == 'retanh':\n",
    "#         _activation = lambda x: np.tanh(x * (x > 0))\n",
    "    \n",
    "#     xh = np.concatenate([x,h], axis=0)\n",
    "#     gate_inputs = np.dot(params[0].T,xh)+params[1]\n",
    "#     noise = 0\n",
    "#     output = _activation(gate_inputs) # + noise\n",
    "\n",
    "#     h_new = (1-alpha) * h + alpha * output\n",
    "    \n",
    "#     return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(m)\n",
    "# with tf.Session() as sess:\n",
    "#     model.restore()\n",
    "#     model._sigma=0\n",
    "#     if len(lesion_units_list)>0:\n",
    "#         model.lesion_units(sess, lesion_units_list)\n",
    "#     hp = model.hp\n",
    "#     alpha = hp['dt']/hp['tau']\n",
    "#     var_list = model.var_list\n",
    "#     params = [sess.run(var) for var in var_list]\n",
    "\n",
    "#     trial = generate_trials(rule, hp, mode='test',noise_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial = gen_trials_from_model_dir(m,'delaygo',noise_on = False)\n",
    "# B = np.shape(trial.y_loc)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:520: calling DatasetV1.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:520: calling DatasetV1.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:523: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:179: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:642: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/Documents/code/flexible_multitask/stepnet/network.py:203: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(148, 128) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(128, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /Users/lauradriscoll/miniconda3/envs/flex_mult/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py:288: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauradriscoll/miniconda3/envs/flex_mult/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1702: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "2024-03-29 02:05:06.842594: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Model restored from file: /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from tools_lnd import find_closest_fp_loc\n",
    "\n",
    "def append_fps(f, h_end, fps_all = [], q_thresh = 1e-2, t_set = []):\n",
    "    \n",
    "    if len(t_set)==0:\n",
    "        t_set = range(0,80,2)\n",
    "    \n",
    "    fp_struct = np.load(f)\n",
    "    fp_use = np.where(fp_struct['qstar']<q_thresh)[0]\n",
    "    x_star = fp_struct['xstar'][fp_use,:]\n",
    "    closest_fp, _ = find_closest_fp_loc(h_end,x_star)\n",
    "    \n",
    "    if trial_num==t_set[0]:\n",
    "        fps_all = x_star[[closest_fp,],:]\n",
    "    else:\n",
    "        fps_all = np.append(fps_all,x_star[[closest_fp,],:],axis = 0) \n",
    "\n",
    "    return fps_all\n",
    "\n",
    "\n",
    "def get_filename_fp(trial, epoch,t):\n",
    "    ind_stim_loc  = 180*trial.y_loc[-1,t]/np.pi\n",
    "    filename = epoch+'_'+str(round(ind_stim_loc,2))+'.npz'\n",
    "\n",
    "    return filename, ind_stim_loc\n",
    "\n",
    "w_in, b_in, w_out, b_out = get_model_params(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(148, 128) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(128, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Model restored from file: /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(148, 128) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(128, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Model restored from file: /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(148, 128) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(128, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n",
      "Model restored from file: /Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/model.ckpt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/lesion_fps_hierarchical_ward_distance_opt_clust/lesion_fps_review/tf_fixed_pts_lesion7/delaydm1/go1_180.0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m     filename,_ \u001b[38;5;241m=\u001b[39m get_filename_fp(trial,epoch,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     84\u001b[0m f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(m,lesion_folder,lf,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_fixed_pts_lesion\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(lesion_cluster),rule,filename)\n\u001b[0;32m---> 85\u001b[0m fps_l \u001b[38;5;241m=\u001b[39m \u001b[43mappend_fps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_l\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrial_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mT_inds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfps_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mq_thresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(m,lesion_folder,lf,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_fixed_pts_lesion\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m0\u001b[39m),rule,filename)\n\u001b[1;32m     89\u001b[0m fps_all \u001b[38;5;241m=\u001b[39m append_fps(f, h_full[:,trial_num,[T_inds[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],]]\u001b[38;5;241m.\u001b[39mT, fps_all \u001b[38;5;241m=\u001b[39m fps_all, \n\u001b[1;32m     90\u001b[0m                      q_thresh \u001b[38;5;241m=\u001b[39m q_thresh, t_set \u001b[38;5;241m=\u001b[39m t_set)\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mappend_fps\u001b[0;34m(f, h_end, fps_all, q_thresh, t_set)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t_set)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     t_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m fp_struct \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m fp_use \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(fp_struct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqstar\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m<\u001b[39mq_thresh)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m x_star \u001b[38;5;241m=\u001b[39m fp_struct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxstar\u001b[39m\u001b[38;5;124m'\u001b[39m][fp_use,:]\n",
      "File \u001b[0;32m~/Documents/code/flexible_multitask/stepnet/task.py:42\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(*a, **k)\u001b[0m\n\u001b[1;32m     40\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# modify the default parameters of np.load\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: \u001b[43mnp_load_old\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Store indices of rules\u001b[39;00m\n\u001b[1;32m     45\u001b[0m rule_index_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/flex_mult/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/lauradriscoll/Documents/data/flexible_multitask/fig3/LeakyRNN_softplus_diag_15_tasks_128_n_rnn_lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo_1/lesion_fps_hierarchical_ward_distance_opt_clust/lesion_fps_review/tf_fixed_pts_lesion7/delaydm1/go1_180.0.npz'"
     ]
    }
   ],
   "source": [
    "from tools_lnd import take_names\n",
    "q_thresh = 1e-2\n",
    "plot_h = 'h'\n",
    "lf = 'lesion_fps_review'\n",
    "\n",
    "plot3 = False\n",
    "plot_zero_plane = False\n",
    "\n",
    "########################\n",
    "########################\n",
    "########################\n",
    "cluster_name_set = ['Continuous Memory','Category Memory']\n",
    "rule_set = ['delaydm1','dmcgo']\n",
    "use_pcs = 'prev_pc'\n",
    "epoch_set =  ['delay1',]\n",
    "# ########################\n",
    "cluster_name_set = ['Anti Stimulus','Delayed Response']\n",
    "rule_set = ['delaygo','delayanti']\n",
    "use_pcs = 'pc'\n",
    "epoch_set = ['stim1',]\n",
    "# ########################\n",
    "cluster_name_set = ['Modality1','Modality2']\n",
    "rule_set = ['delaydm1','delaydm2']\n",
    "use_pcs = 'prev_pc'\n",
    "epoch_set = ['delay1',]\n",
    "########################\n",
    "########################\n",
    "########################\n",
    "epoch_set = ['go1',]\n",
    "use_pcs = 'prev_pc'\n",
    "plot3 = True\n",
    "plot_zero_plane = True\n",
    "\n",
    "for cluster_name in cluster_name_set:\n",
    "    \n",
    "    if cluster_name == 'Category Memory':\n",
    "        lesion_cluster = 20\n",
    "        lesion_units_list = []\n",
    "        [lesion_units_list.append(x) for x in cluster_var['lesion_units_list'][20]] # \n",
    "        [lesion_units_list.append(x) for x in cluster_var['lesion_units_list'][21]] # \n",
    "    elif cluster_name == 'Continuous Memory':\n",
    "        lesion_cluster = 1\n",
    "        lesion_units_list = []\n",
    "        [lesion_units_list.append(x) for x in cluster_var['lesion_units_list'][1]] # \n",
    "        [lesion_units_list.append(x) for x in cluster_var['lesion_units_list'][2]] # \n",
    "        \n",
    "    else:\n",
    "        lesion_cluster = cluster_number[cluster_name]+1\n",
    "        lesion_units_list = cluster_var['lesion_units_list'][lesion_cluster]\n",
    "\n",
    "    for rule in rule_set:\n",
    "        \n",
    "        trial = gen_trials_from_model_dir(m,rule,mode='test',noise_on = False)\n",
    "        _,h_l = gen_X_from_model_dir(m,trial,lesion_units_list = lesion_units_list)\n",
    "        _,h_full = gen_X_from_model_dir(m,trial)\n",
    "\n",
    "        B = np.shape(trial.y_loc)[1]\n",
    "        t_set = range(3,int(B),int(B/40))\n",
    "#         t_set = range(int(B))\n",
    "\n",
    "        for epoch in epoch_set: \n",
    "\n",
    "            T_inds = get_T_inds(trial,epoch) #get indices of epoch\n",
    "\n",
    "            #if trials have diff inputs, concat fps from diff trials\n",
    "            if np.any(np.diff(trial.x[T_inds[0],:,:],axis = 0)):\n",
    "                skip_trials = 2\n",
    "            else:\n",
    "                skip_trials = int(B)\n",
    "\n",
    "            #Make fp_set\n",
    "            fps_l = []\n",
    "            fps_all = []\n",
    "\n",
    "            for trial_num in t_set:\n",
    "\n",
    "#                 out_theta = int(180*trial.y_loc[-1,trial_num]/np.pi)\n",
    "                \n",
    "                if np.any(np.diff(trial.x[T_inds[0],:,:],axis = 0)):\n",
    "                    filename,_ = get_filename_fp(trial,epoch,trial_num)\n",
    "                else:\n",
    "                    filename,_ = get_filename_fp(trial,epoch,0)\n",
    "\n",
    "                f = os.path.join(m,lesion_folder,lf,'tf_fixed_pts_lesion'+str(lesion_cluster),rule,filename)\n",
    "                fps_l = append_fps(f, h_l[:,trial_num,[T_inds[-1],]].T, fps_all = fps_l, \n",
    "                                   q_thresh = q_thresh, t_set = t_set)\n",
    "\n",
    "                f = os.path.join(m,lesion_folder,lf,'tf_fixed_pts_lesion'+str(0),rule,filename)\n",
    "                fps_all = append_fps(f, h_full[:,trial_num,[T_inds[-1],]].T, fps_all = fps_all, \n",
    "                                     q_thresh = q_thresh, t_set = t_set)\n",
    "\n",
    "            #####do PCA on combined fps for viz axes\n",
    "            if use_pcs=='fp':\n",
    "                pca = PCA(n_components = 10)\n",
    "                fps_pc = pca.fit_transform(np.append(fps_all,fps_l,axis = 0) )\n",
    "\n",
    "                D_all = pca.components_\n",
    "                x_label = 'combined FP PC1'\n",
    "                y_label = 'combined FP PC2'\n",
    "                axes_labels = [x_label,y_label]\n",
    "            elif use_pcs=='out':\n",
    "                D_all = w_out[:,1:].T\n",
    "\n",
    "                x_label = 'output 1'\n",
    "                y_label = 'output 2'\n",
    "                axes_labels = [x_label,y_label]\n",
    "            elif use_pcs=='prev_pc':\n",
    "                pca = PCA(n_components = 10)\n",
    "                h_cat = np.append(h_full[:,:,T_inds[0]-1],h_l[:,:,T_inds[0]-1],axis = 1).T\n",
    "                fps_pc = pca.fit_transform(h_cat)\n",
    "\n",
    "                D_all = pca.components_\n",
    "                D_all[0,:] = -D_all[0,:]\n",
    "                x_label = 'combined h0 PC1'\n",
    "                y_label = 'combined h0 PC2'\n",
    "                axes_labels = [x_label,y_label]\n",
    "            else:\n",
    "                pca = PCA(n_components = 10)\n",
    "                h_cat = np.append(h_full[:,:,T_inds[-1]],h_l[:,:,T_inds[-1]],axis = 1).T\n",
    "                fps_pc = pca.fit_transform(h_cat)\n",
    "\n",
    "                D_all = pca.components_\n",
    "                x_label = 'combined h_end PC1'\n",
    "                y_label = 'combined h_end PC2'\n",
    "                axes_labels = [x_label,y_label]\n",
    "                \n",
    "            \n",
    "            #PLOT FPS\n",
    "            if plot3:\n",
    "                fig = plt.figure(figsize=(4,4),tight_layout=True,facecolor='white')\n",
    "                ax = fig.add_axes([0,0,1,1], projection='3d');\n",
    "            else:\n",
    "                fig = plt.figure(figsize=(4,4),tight_layout=True,facecolor='white')\n",
    "                ax = plt.subplot(1,1,1)\n",
    "                \n",
    "            al = .2\n",
    "\n",
    "            if plot_h:\n",
    "                for t in t_set:\n",
    "                    \n",
    "                    if plot3:\n",
    "\n",
    "                        if plot_zero_plane:\n",
    "                            D3 = np.concatenate((D_all[:2,:],w_out[:,1:2].T))\n",
    "                        else:\n",
    "                            D3 = np.concatenate((D_all[:3,:],w_out[:,1:2].T))\n",
    "                            axes_labels.append(axes_labels[1][:-1]+'3')\n",
    "                        \n",
    "                        h = h_full[:,t,T_inds]\n",
    "                        h_in_D = np.dot(D3,h)\n",
    "                        ax.plot3D(h_in_D[0,:],h_in_D[1,:],h_in_D[2,:],'-', c = 'dodgerblue',linewidth = 3, alpha = al)\n",
    "#                         ax.scatter(h_in_D[0,0],h_in_D[1,0],h_in_D[2,0],'x', c = 'dodgerblue',linewidth = 3, alpha = al, s = 10)\n",
    "#                         ax.scatter(h_in_D[0,-1],h_in_D[1,-1],h_in_D[2,-1],'^', c = 'dodgerblue',linewidth = 3, alpha = al)\n",
    "\n",
    "                        h = h_l[:,t,T_inds]\n",
    "                        h_in_D = np.dot(D3,h)\n",
    "                        ax.plot3D(h_in_D[0,:],h_in_D[1,:],h_in_D[2,:],'-', c = 'orangered',linewidth = 3, alpha = al)\n",
    "#                         ax.scatter(h_in_D[0,0],h_in_D[1,0],h_in_D[2,0],'x', c = 'orangered',linewidth = 3, alpha = al, s = 10)\n",
    "#                         ax.scatter(h_in_D[0,-1],h_in_D[1,-1],h_in_D[2,-1],'^', c = 'orangered',linewidth = 3, alpha = al)\n",
    "                        \n",
    "                    else:\n",
    "                        h = h_full[:,t,T_inds]\n",
    "                        h_in_D = np.dot(D_all,h)\n",
    "                        plt.plot(h_in_D[0,:],h_in_D[1,:],'-', c = 'dodgerblue',linewidth = 3, alpha = al)\n",
    "                        plt.plot(h_in_D[0,0],h_in_D[1,0],'x', c = 'dodgerblue',linewidth = 3, alpha = al, markersize = 10)\n",
    "                        plt.plot(h_in_D[0,-1],h_in_D[1,-1],'^', c = 'dodgerblue',linewidth = 3, alpha = al, markersize = 10)\n",
    "\n",
    "                        h = h_l[:,t,T_inds]\n",
    "                        h_in_D = np.dot(D_all,h)\n",
    "                        plt.plot(h_in_D[0,:],h_in_D[1,:],'-', c = 'orangered',linewidth = 3, alpha = al)\n",
    "                        plt.plot(h_in_D[0,0],h_in_D[1,0],'x', c = 'orangered',linewidth = 3, alpha = al, markersize = 10)\n",
    "                        plt.plot(h_in_D[0,-1],h_in_D[1,-1],'^', c = 'orangered',linewidth = 3, alpha = al, markersize = 10)\n",
    "\n",
    "            \n",
    "            \n",
    "            if plot3:\n",
    "                fp_in_D_all = np.dot(D3,fps_all.T)\n",
    "                fp_in_D_l = np.dot(D3,fps_l.T)\n",
    "                ax.scatter(fp_in_D_all[0,:],fp_in_D_all[1,:],fp_in_D_all[2,:],'o', c = 'dodgerblue',alpha = .8, s = 20)\n",
    "                ax.scatter(fp_in_D_l[0,:],fp_in_D_l[1,:],fp_in_D_l[2,:],'o', c = 'orangered',alpha = .8, s = 20)\n",
    "            else:\n",
    "                fp_in_D_all = np.dot(D_all,fps_all.T)\n",
    "                fp_in_D_l = np.dot(D_all,fps_l.T)\n",
    "                plt.plot(fp_in_D_all[0,:],fp_in_D_all[1,:],'o', c = 'dodgerblue',alpha = .8)#, markersize = 10)\n",
    "                plt.plot(fp_in_D_l[0,:],fp_in_D_l[1,:],'o', c = 'orangered',alpha = .8)#, markersize = 10)\n",
    "\n",
    "\n",
    "            if plot3:\n",
    "                if plot_zero_plane:\n",
    "\n",
    "                    [x1,x2] = ax.get_xlim()\n",
    "                    [y1,y2] = ax.get_ylim()\n",
    "\n",
    "                    zlabel = 'out_null'\n",
    "                    save_axes = zlabel\n",
    "                    xx, yy = np.meshgrid(np.linspace(x1, x2, num=2), np.linspace(y1, y2, num=2))\n",
    "                    z = xx*0\n",
    "                    ax.plot_surface(xx, yy, z, alpha=0.1)\n",
    "                    ax.set_zlabel(r\"$\\bf{Output}$\"+r'$\\cos{\\theta}$',labelpad=-10, fontsize = 16)\n",
    "#                 ax.text(x1, y1, 0, 'Output Null', (1,0,0))\n",
    "                    ax.set_zlim([-.9,.9])\n",
    "                \n",
    "                else:\n",
    "                    ax.set_zlabel(axes_labels[2],fontsize = 16)\n",
    "                \n",
    "                ax.set_xlabel(axes_labels[0],fontsize = 16)\n",
    "                ax.set_ylabel(axes_labels[1],fontsize = 16)\n",
    "                ax.set_zticks([])\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.dist = 12\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                make_lil_axes(ax,axes_labels,fontsize = 16,fac_len = 1)\n",
    "                \n",
    "            epoch_name, rule_name, _, _ = take_names(epoch,rule,epoch_axes = epoch, h_epoch = epoch)\n",
    "            tit = 'Lesion: '+ cluster_name + ' \\n Task: ' + rule_name + ' \\n Period: ' +epoch_name\n",
    "            plt.title(tit,fontsize = 18,y = .9)\n",
    "\n",
    "            #save figs\n",
    "            if plot3:\n",
    "                figname = '_'.join(('plot3',cluster_name,rule_name,epoch_name,x_label))\n",
    "            else:\n",
    "                figname = '_'.join((cluster_name,rule_name,epoch_name,x_label))\n",
    "                \n",
    "#             plt.tight_layout()    \n",
    "            plt.savefig(os.path.join(figpath,figname+'.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
